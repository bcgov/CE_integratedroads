#!/bin/bash
set -euxo pipefail

# ----
# For file based source data, download/tile/upload to objectstore
# ----

mkdir -p tmp

# DRA

# Download
# We use the non-public copy DRA because the public dataset's schema does not match
# the schema used in these queries. Below extracts only the public portion of the data
curl \
  -o /tmp/transport_line.gdb.zip \
  https://nrs.objectstore.gov.bc.ca/itqlyp/GBA/PROVINCE/transport_line.gdb.zip

# extract password protected zipfile
unzip \
  -P $DRAPWD \
  -d /tmp \
  -o \
  /tmp/transport_line.gdb.zip

ogr2ogr \
  -f Parquet \
  tmp/whse_basemapping.transport_line.parquet \
  -select TRANSPORT_LINE_ID,STRUCTURED_NAME_1,STRUCTURED_NAME_1_ID,CAPTURE_DATE,TOTAL_NUMBER_OF_LANES,TRANSPORT_LINE_STRUCTURE_CODE,TRANSPORT_LINE_TYPE_CODE,TRANSPORT_LINE_SURFACE_CODE \
  -unsetFid \
  -dim XY \
  -where "TRANSPORT_LINE_SURFACE_CODE <> 'B'" \
  /tmp/transport_line.gdb \
  TRANSPORT_LINE

# presume tiles are already present on s3
python scripts/intersect.py \
  tmp/whse_basemapping.transport_line.parquet \
  s3://$OBJECTSTORE_BUCKET/whse_basemapping.bcgs_20k_grid.parquet \
  s3://$OBJECTSTORE_BUCKET/whse_basemapping.transport_line.parquet \
  --sort_by map_tile

# dump dra code tables to csv and send to s3 vis awscli
ogr2ogr \
  -f CSV \
  tmp/whse_basemapping.transport_line_structure_code.csv \
  /tmp/transport_line.gdb \
  TRANSPORT_LINE_STRUCTURE_CODE

ogr2ogr \
  -f CSV \
  tmp/whse_basemapping.transport_line_type_code.csv \
  /tmp/transport_line.gdb \
  TRANSPORT_LINE_TYPE_CODE

ogr2ogr \
  -f CSV \
  tmp/whse_basemapping.transport_line_surface_code.csv \
  /tmp/transport_line.gdb \
  TRANSPORT_LINE_SURFACE_CODE

aws s3 cp tmp/whse_basemapping.transport_line_structure_code.csv s3://$OBJECTSTORE_BUCKET
aws s3 cp tmp/whse_basemapping.transport_line_type_code.csv s3://$OBJECTSTORE_BUCKET
aws s3 cp tmp/whse_basemapping.transport_line_surface_code.csv s3://$OBJECTSTORE_BUCKET
