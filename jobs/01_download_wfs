#!/bin/bash
set -euxo pipefail

# ----
# Download BC WFS datasets to file
# ----

bcdata dump -v --lowercase whse_basemapping.bcgs_20k_grid |
    ogr2ogr -f Parquet \
      -sql "select map_tile, substr(map_tile, 1, 4) as map_tile_250 from OGRGeoJSON" \
      /vsis3/$BUCKET/whse_basemapping.bcgs_20k_grid.parquet \
      /vsistdin/

# download WFS datasets to parquet
python scripts/bc2parquet.py bcdata.json -v

# overlay each source with tiles, write to S3
jq -c '.[]' bcdata.json | while read item; do
    SOURCE=$(jq -r '.dataset' <<< "$item")
    
    # overlay with tiles, sort by tile id, write to s3
    python scripts/intersect.py \
        $SOURCE.parquet \
        s3://$BUCKET/whse_basemapping.bcgs_20k_grid.parquet \
        s3://$BUCKET/$SOURCE.parquet \
        --sort_by map_tile

done

